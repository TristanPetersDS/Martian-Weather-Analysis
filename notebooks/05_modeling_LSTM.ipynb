{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb03088-3f70-4568-a141-7732aefdaaac",
   "metadata": {},
   "source": [
    "# Step 3: LSTM Forecasting + Residual Anomaly Detection\n",
    "\n",
    "In this section we:\n",
    "\n",
    "1. Load our scaled data and the original `MinMaxScaler`  \n",
    "2. Build Keras `TimeseriesGenerator`s  \n",
    "3. Define & train an LSTM model  \n",
    "4. Forecast & evaluate (MAE, RMSE, MAPE, directional accuracy)  \n",
    "5. Flag anomalies via a 3σ threshold on residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f017d90-bbc7-498e-972c-22873e9ea54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746699399.035441 2251644 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746699399.039142 2251644 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746699399.048894 2251644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746699399.048901 2251644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746699399.048902 2251644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746699399.048903 2251644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "I0000 00:00:1746699401.169353 2251644 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9554 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0000 00:00:1746699403.130647 2251970 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3.1 Imports & Data Loading\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Silence that specific PyDataset warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=UserWarning\n",
    ")\n",
    "\n",
    "# Full suppression of GPU logs at OS level\n",
    "sys.stderr = open(os.devnull, \"w\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.utilities import save_model_outputs\n",
    "\n",
    "\n",
    "\n",
    "ABS_PATH      = \"/home/tristan/Desktop/SpringBoard/Projects/Martian-Weather-Analysis/\"\n",
    "DATA_PATH     = os.path.join(ABS_PATH, \"data/processed/\")\n",
    "MODEL_PATH    = os.path.join(ABS_PATH, \"models/\")\n",
    "LOG_PATH_ROOT = os.path.join(ABS_PATH, \"logs/\")\n",
    "lstm_log_path = os.path.join(LOG_PATH_ROOT, \"lstm_training.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0ec272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSequence(Sequence):\n",
    "    def __init__(self, reg_gen, clf_gen):\n",
    "        self.reg_gen = reg_gen\n",
    "        self.clf_gen = clf_gen\n",
    "        assert len(self.reg_gen) == len(self.clf_gen)\n",
    "    def __len__(self):\n",
    "        return len(self.reg_gen)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y_reg = self.reg_gen[idx]\n",
    "        _, y_clf = self.clf_gen[idx]\n",
    "        return x, {\"forecast\": y_reg, \"direction\": y_clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b121cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scaled data\n",
    "'''Note: \n",
    "These data ssets were scaled on all the features at once. \n",
    "This could potentially posse an issue later on.\n",
    "It might be worth simply reprocessing this data and adding it to the preprocessing phase notebook later.'''\n",
    "X_scaled_train = pd.read_csv(os.path.join(DATA_PATH, \"scaled_train.csv\"), index_col=\"sol_number\")\n",
    "X_scaled_test  = pd.read_csv(os.path.join(DATA_PATH, \"scaled_test.csv\"),  index_col=\"sol_number\")\n",
    "X_unscaled_test= pd.read_csv(os.path.join(DATA_PATH, \"unscaled_test.csv\"),index_col=\"sol_number\")\n",
    "\n",
    "# Raw train/test target for metrics & direction labels\n",
    "y_train_raw = pd.read_csv(os.path.join(DATA_PATH, \"unscaled_train.csv\"),\n",
    "                          index_col=\"sol_number\")[\"avg_ground_temp\"].values\n",
    "y_test_raw  = X_unscaled_test[\"avg_ground_temp\"].values\n",
    "\n",
    "# Precompute rise/fall/no-change labels for the ENTIRE train & test series\n",
    "train_diff   = np.sign(np.diff(y_train_raw,  prepend=y_train_raw[0]))\n",
    "train_dir_lbl= to_categorical(\n",
    "    np.where(train_diff>0, 0, np.where(train_diff<0, 1, 2)),\n",
    "    num_classes=3\n",
    ")\n",
    "\n",
    "test_diff    = np.sign(np.diff(y_test_raw,   prepend=y_test_raw[0]))\n",
    "test_dir_lbl = to_categorical(\n",
    "    np.where(test_diff>0,  0, np.where(test_diff<0, 1, 2)),\n",
    "    num_classes=3\n",
    ")\n",
    "\n",
    "# Load target variable scaler object\n",
    "y_scaler_target = joblib.load(os.path.join(MODEL_PATH, \"y_target_scaler.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf638aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare feature and target arrays\n",
    "DROPPED = [\"avg_ground_temp\"]\n",
    "FEATURE_COLS = [c for c in X_scaled_train.columns if c not in DROPPED]\n",
    "\n",
    "feature_sets = {\n",
    "    \"uni\":      [],  # pure univariate\n",
    "    \"multi\":    FEATURE_COLS\n",
    "}\n",
    "\n",
    "param_grid = [\n",
    "    (seq, units, drp, name, cols)\n",
    "    for seq in (10,15,20,25,30,60)\n",
    "    for units in (5,10,15,20,25,32,50,75)\n",
    "    for drp in (0.1,0.2,0.3)\n",
    "    for name, cols in feature_sets.items()\n",
    "]\n",
    "\n",
    "n_models = len(param_grid)\n",
    "\n",
    "# Prepare log\n",
    "grid_log = open(os.path.join(LOG_PATH_ROOT, \"lstm_grid_search.log\"), \"w\")\n",
    "grid_log.write(\"LSTM Grid Search Log\\n\" + \"=\"*60 + \"\\n\")\n",
    "grid_log.write(f\"Started: {datetime.now():%Y-%m-%d %H:%M:%S}\\n\")\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    (seq, units, drp, name, cols)\n",
    "    for seq in (10,15,20,25,30,60)\n",
    "    for units in (5,10,15,20,25,32,50,75)\n",
    "    for drp in (0.1,0.2,0.3)\n",
    "    for name, cols in feature_sets.items()\n",
    "]\n",
    "\n",
    "n_models = len(param_grid)\n",
    "\n",
    "# Prepare log\n",
    "grid_log = open(os.path.join(LOG_PATH_ROOT, \"lstm_grid_search.log\"), \"w\")\n",
    "grid_log.write(\"LSTM Grid Search Log\\n\" + \"=\"*60 + \"\\n\")\n",
    "grid_log.write(f\"Started: {datetime.now():%Y-%m-%d %H:%M:%S}\\n\")\n",
    "grid_log.write(f\"Total models: {n_models}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8744feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Grid Search: 100%|████████████████████| 288/288 [26:57<00:00,  5.62s/model]\n",
      "\n",
      "Best LSTM Configuration\n",
      "========================================\n",
      "Feature Set     : uni\n",
      "Sequence Length : 15\n",
      "LSTM Units      : 25\n",
      "Dropout Rate    : 0.10\n",
      "MAE             : 1.707 °C\n",
      "RMSE            : 2.870 °C\n",
      "sMAPE           : 4.05 %\n",
      "Dir. Accuracy   : 46.56 %\n",
      "Selection Score : 2.776\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Track best model\n",
    "best_model      = None\n",
    "best_params     = None\n",
    "best_mae        = np.inf\n",
    "best_rmse       = np.inf\n",
    "best_dir_acc    = 0\n",
    "best_score      = np.inf  # Combined score: lower is better\n",
    "\n",
    " # Add smape\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "\n",
    "# Grid search\n",
    "for seq_len, units, dropout, fs_name, cols in tqdm(\n",
    "    param_grid,\n",
    "    desc=\"LSTM Grid Search\",\n",
    "    ncols=80,\n",
    "    unit=\"model\",\n",
    "    leave=True,\n",
    "    file=sys.stdout\n",
    "):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Prepare targets\n",
    "    y_train_scaled = y_scaler_target.transform(y_train_raw.reshape(-1, 1)).flatten()\n",
    "    y_test_scaled  = y_scaler_target.transform(y_test_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Prepare feature arrays and enforce float32\n",
    "    if cols:\n",
    "        X_tr = X_scaled_train[cols].values.astype(np.float32)\n",
    "        X_te = X_scaled_test[cols].values.astype(np.float32)\n",
    "    else:\n",
    "        # Use avg_ground_temp as the univariate feature\n",
    "        X_tr = X_scaled_train[[\"avg_ground_temp\"]].values.astype(np.float32)\n",
    "        X_te = X_scaled_test[[\"avg_ground_temp\"]].values.astype(np.float32)\n",
    "    assert X_tr.dtype == np.float32 and X_te.dtype == np.float32, \"Data must be float32\"\n",
    "    assert not np.isnan(X_tr).any() and not np.isnan(X_te).any(), \"Input data contains NaNs\"\n",
    "\n",
    "\n",
    "    # Timeseries Generators + CombinedSequence\n",
    "    reg_train = TimeseriesGenerator(X_tr, y_train_scaled, length=seq_len, batch_size=32)\n",
    "    clf_train = TimeseriesGenerator(X_tr, train_dir_lbl,  length=seq_len, batch_size=32)\n",
    "    reg_test  = TimeseriesGenerator(X_te, y_test_scaled,  length=seq_len, batch_size=32)\n",
    "    clf_test  = TimeseriesGenerator(X_te, test_dir_lbl,   length=seq_len, batch_size=32)\n",
    "    train_seq = CombinedSequence(reg_train, clf_train)\n",
    "    test_seq  = CombinedSequence(reg_test,  clf_test)\n",
    "\n",
    "    # Build model: CuDNN-compatible LSTM\n",
    "    inp     = Input(shape=(seq_len, X_tr.shape[1]))\n",
    "    x       = LSTM(\n",
    "        units,\n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "        use_bias=True,\n",
    "        unroll=False,\n",
    "        return_sequences=False,\n",
    "        dropout=0.0  # Must be 0 for GPU CuDNN compatibility\n",
    "    )(inp)\n",
    "    x       = Dropout(dropout)(x)  # External dropout layer\n",
    "    out_reg = Dense(1, activation=None,      name=\"forecast\")(x)\n",
    "    out_clf = Dense(3, activation=\"softmax\", name=\"direction\")(x)\n",
    "    model   = Model(inp, [out_reg, out_clf])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\"forecast\": \"mse\", \"direction\": \"categorical_crossentropy\"},\n",
    "        metrics={\"forecast\": \"mae\", \"direction\": \"accuracy\"}\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_forecast_loss\", mode=\"min\", patience=3, restore_best_weights=True)\n",
    "    model.fit(train_seq, validation_data=test_seq, epochs=30, callbacks=[es], verbose=0)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred_scaled, _ = model.predict(test_seq, verbose=0)\n",
    "    y_pred = y_scaler_target.inverse_transform(y_pred_scaled).flatten()\n",
    "    y_true = y_test_raw[seq_len:]\n",
    "    mae    = mean_absolute_error(y_true, y_pred)\n",
    "    rmse   = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    smape_ = smape(y_true, y_pred)\n",
    "\n",
    "    preds_dir = np.argmax(model.predict(test_seq, verbose=0)[1], axis=1)\n",
    "    true_dir  = np.argmax(test_dir_lbl[seq_len:], axis=1)\n",
    "    dir_acc   = (preds_dir == true_dir).mean() * 100\n",
    "\n",
    "    # Combined selection score\n",
    "    score = mae + 0.02 * (100 - dir_acc)\n",
    "\n",
    "    # Log the result\n",
    "    grid_log.write(\n",
    "        f\"{fs_name:6s} | seq={seq_len:<2d} | units={units:<3d} | drop={dropout:<4.2f} \"\n",
    "        f\"→ MAE={mae:.3f} °C | RMSE={rmse:.3f} °C | DirAcc={dir_acc:5.1f}% | Score={score:.3f}\\n\"\n",
    "    )\n",
    "    grid_log.flush()\n",
    "\n",
    "    # Save best if improved\n",
    "    if score < best_score:\n",
    "        best_score   = score\n",
    "        best_model   = model\n",
    "        best_mae     = mae\n",
    "        best_rmse    = rmse\n",
    "        best_dir_acc = dir_acc\n",
    "        best_smape   = smape_\n",
    "        best_params  = (seq_len, units, dropout, fs_name, cols)\n",
    "        best_y_pred  = y_pred\n",
    "        best_y_test  = y_true\n",
    "\n",
    "\n",
    "# Finalize log\n",
    "grid_log.close()\n",
    "\n",
    "# Save best model\n",
    "best_model_path = os.path.join(MODEL_PATH, \"best_lstm_model.keras\")\n",
    "best_model.save(best_model_path)\n",
    "\n",
    "# Print best config\n",
    "seq_len, units, dropout, fs_name, _ = best_params\n",
    "print(\"\\nBest LSTM Configuration\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Feature Set     : {fs_name}\")\n",
    "print(f\"Sequence Length : {seq_len}\")\n",
    "print(f\"LSTM Units      : {units}\")\n",
    "print(f\"Dropout Rate    : {dropout:.2f}\")\n",
    "print(f\"MAE             : {best_mae:.3f} °C\")\n",
    "print(f\"RMSE            : {best_rmse:.3f} °C\")\n",
    "print(f\"sMAPE           : {best_smape:.2f} %\")\n",
    "print(f\"Dir. Accuracy   : {best_dir_acc:.2f} %\")\n",
    "print(f\"Selection Score : {best_score:.3f}\")\n",
    "print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11c4fc8-8305-4f29-b751-c1ed07d0b034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs for LSTM to model_outputs/\n"
     ]
    }
   ],
   "source": [
    "# Save details of model for later use\n",
    "save_model_outputs(\n",
    "    model_name=\"LSTM\",\n",
    "    y_true=best_y_test,\n",
    "    y_pred=best_y_pred,\n",
    "    metrics={\"mae\":            best_mae, \n",
    "             \"rmse\":           best_rmse,\n",
    "             \"smape\":          best_smape,\n",
    "             \"Dir. Accuracy \": best_dir_acc}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4878c-f3a0-4344-acb2-87d2e76f8eaa",
   "metadata": {},
   "source": [
    "## 3.4 Forecasting & Metrics\n",
    "\n",
    "We’ll predict on `test_gen`, invert the scaling, then compute MAE, RMSE, MAPE, and directional accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
